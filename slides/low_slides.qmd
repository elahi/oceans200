---
title: "Reviewing some essentials"
author: "Robin Elahi"
format: revealjs
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# Set working directory
knitr::opts_knit$set(root.dir = "../")
```

## Course overview

## Prerequisites

You have some familiarity with R computing and statistics. 

. . .

For instance, you should be able to figure out what this means:
```{r intro}
x <- c(2, 4, 3, 6)
y <- c(5, 12, 4, 10, 2)
t.test(x, y)
```


## Statistics vs parameters

. . .

A **statistic** is

:   a numerical description of a sample

. . .

A **parameter** is

:   a numerical attribute of a population

. . .

Often, *statistics* are used to estimate *parameters*.


## The two heads of classical statistics

estimating parameters, with uncertainty *(confidence intervals)*

evaluating (in-)consistency with a particular situation *($p$-values)*

. . .

1. What do these data tell us about the world?
2. How strongly do we believe it?


. . .

*This week:* digging in, with simple examples.


## Lurking, behind everything:

is *uncertainty*

. . .

thanks to *randomness*.

. . .

How do we understand randomness, concretely and quantitatively?

. . .

With *models*.

## Data story

Low et al (2016) examined the effects of two different anesthetics on aspects of the physiology of the mouse. Twelve mice were anesthetized with isoflurane and eleven mice were anesthetized with alpha chloralose and blood CO~2~ levels were recorded after 120 minutes. The H~0~ was that there was no difference between the anesthetics in the mean blood CO~2~ level. This is an independent comparison because individual mice were only given one of the two anesthetics.

## R

```{r packages}
library(tidyverse)
library(car)

theme_set(theme_bw(base_size = 16) + 
            theme(panel.grid.minor = element_blank(), 
                  strip.background = element_blank()))
```

## The data

Describe what is happening in these lines of code.

```{r}
low <- read.csv("data/lowco2.csv")
```

Â 

. . .

```{r}
names(low)
```

\

. . .

```{r}
dim(low)
```

\

. . .

```{r}
str(low)
```

## Visualize data

```{r}
low %>% 
  ggplot(aes(anesth, co2)) + 
  geom_point(alpha = 0.5, size = 5) + 
  labs(x = "Anesthetic", y = "CO2") + 
  theme_bw(base_size = 24)
```



## Summarizing data: point estimates and variability

```{r}
low %>%  
  group_by(anesth) %>% 
  summarise(n = n(), 
            mean = mean(co2),
            median = median(co2),
            sd = sd(co2), 
            variance = var(co2), 
            se = sd / sqrt(n)
            )
```

**Your turn**.\
Add to the `summarise` function to calculate the 95% confidence interval for each treatment using `qt`. Interpret the CI. You should get the same answer as in the book.

## Confidence intervals

```{r}
low %>%  
  group_by(anesth) %>% 
  summarise(n = n(), 
            mean = mean(co2),
            sd = sd(co2), 
            se = sd / sqrt(n), 
            CI_upper = mean + se * qt(p = 0.975, df = n-1), 
            CI_lower = mean + se * qt(p = 0.025, df = n-1), 
            CI = se * qt(p = 0.975, df = n-1), 
            upper = mean + CI, 
            lower = mean - CI
            )
```

In a frequentist world, parameters are fixed (but unknowable). Interpret the CI in this context.

## Hypothesis testing

A. Construct a null hypothesis (H~O~)

B. Derive a test statistic from the data

C. Compare the obtained test statistic to one derived from values obtained under the H~O~. 

## A $p$-value is

. . .

> the probability of seeing a result at least as surprising
> as what was observed in the data,
> if the null hypothesis is true.

. . .

Usually, this means

- *a result* - numerical value of a statistic
- *surprising* - big
- *null hypothesis* - the model we use to calculate the $p$-value

which can all be defined to suit the situation.

## What does a small $p$-value mean?

*If* the null hypothesis *was* true,
then you'd be really unlikely to see something like what you actually *did*.

. . .

So, either the "null hypothesis" is not a good description of reality
or something surprising happened.

. . .

How useful this is depends on the null hypothesis.


## ANOVA

```{r}
low.aov <- aov(co2~anesth,data=low)
summary(low.aov)
```

## Test variances

```{r}
leveneTest(co2 ~ anesth, low)
```

## T-test: equal variances

```{r}
t.test(co2 ~ anesth, var.equal = TRUE, data = low)
```

## T-test: separate variances

```{r}
t.test(co2 ~ anesth, data = low)
```

## Wilcoxon-Mann-Whitney

```{r}
wilcox.test(co2~anesth,data=low)
sum(rank(low$co2)[low$anesth=="ac"])
sum(rank(low$co2)[low$anesth=="iso"])
```


